Welcome to Siyuan's Feature Selection Algorithm.

Enter dataset filename: 
This dataset has 10 features (not including the class attribute), with 100 instances.

Running nearest neighbor with no features (random baseline), using "leaving-one-out" evaluation, I get an accuracy of 50.0%

Type the number of the algorithm you want to run.

     1) Forward Selection
     2) Backward Elimination

Your choice: Beginning search.

Using feature(s) {1,2,3,4,5,6,7,8,9,10} accuracy is 65.0%

Feature set {1,2,3,4,5,6,7,8,9,10} was best, accuracy is 65.0%

Using feature(s) {2,3,4,5,6,7,8,9,10} accuracy is 69.0%
Using feature(s) {1,3,4,5,6,7,8,9,10} accuracy is 66.0%
Using feature(s) {1,2,4,5,6,7,8,9,10} accuracy is 75.0%
Using feature(s) {1,2,3,5,6,7,8,9,10} accuracy is 68.0%
Using feature(s) {1,2,3,4,6,7,8,9,10} accuracy is 71.0%
Using feature(s) {1,2,3,4,5,7,8,9,10} accuracy is 69.0%
Using feature(s) {1,2,3,4,5,6,8,9,10} accuracy is 61.0%
Using feature(s) {1,2,3,4,5,6,7,9,10} accuracy is 70.0%
Using feature(s) {1,2,3,4,5,6,7,8,10} accuracy is 67.0%
Using feature(s) {1,2,3,4,5,6,7,8,9} accuracy is 70.0%

Feature set {1,2,4,5,6,7,8,9,10} was best, accuracy is 75.0%

Using feature(s) {2,4,5,6,7,8,9,10} accuracy is 73.0%
Using feature(s) {1,4,5,6,7,8,9,10} accuracy is 74.0%
Using feature(s) {1,2,5,6,7,8,9,10} accuracy is 71.0%
Using feature(s) {1,2,4,6,7,8,9,10} accuracy is 64.0%
Using feature(s) {1,2,4,5,7,8,9,10} accuracy is 77.0%
Using feature(s) {1,2,4,5,6,8,9,10} accuracy is 65.0%
Using feature(s) {1,2,4,5,6,7,9,10} accuracy is 70.0%
Using feature(s) {1,2,4,5,6,7,8,10} accuracy is 74.0%
Using feature(s) {1,2,4,5,6,7,8,9} accuracy is 68.0%

Feature set {1,2,4,5,7,8,9,10} was best, accuracy is 77.0%

Using feature(s) {2,4,5,7,8,9,10} accuracy is 77.0%
Using feature(s) {1,4,5,7,8,9,10} accuracy is 74.0%
Using feature(s) {1,2,5,7,8,9,10} accuracy is 63.0%
Using feature(s) {1,2,4,7,8,9,10} accuracy is 59.0%
Using feature(s) {1,2,4,5,8,9,10} accuracy is 69.0%
Using feature(s) {1,2,4,5,7,9,10} accuracy is 78.0%
Using feature(s) {1,2,4,5,7,8,10} accuracy is 74.0%
Using feature(s) {1,2,4,5,7,8,9} accuracy is 71.0%

Feature set {1,2,4,5,7,9,10} was best, accuracy is 78.0%

Using feature(s) {2,4,5,7,9,10} accuracy is 76.0%
Using feature(s) {1,4,5,7,9,10} accuracy is 74.0%
Using feature(s) {1,2,5,7,9,10} accuracy is 68.0%
Using feature(s) {1,2,4,7,9,10} accuracy is 65.0%
Using feature(s) {1,2,4,5,9,10} accuracy is 74.0%
Using feature(s) {1,2,4,5,7,10} accuracy is 80.0%
Using feature(s) {1,2,4,5,7,9} accuracy is 75.0%

Feature set {1,2,4,5,7,10} was best, accuracy is 80.0%

Using feature(s) {2,4,5,7,10} accuracy is 82.0%
Using feature(s) {1,4,5,7,10} accuracy is 72.0%
Using feature(s) {1,2,5,7,10} accuracy is 73.0%
Using feature(s) {1,2,4,7,10} accuracy is 61.0%
Using feature(s) {1,2,4,5,10} accuracy is 72.0%
Using feature(s) {1,2,4,5,7} accuracy is 77.0%

Feature set {2,4,5,7,10} was best, accuracy is 82.0%

Using feature(s) {4,5,7,10} accuracy is 78.0%
Using feature(s) {2,5,7,10} accuracy is 79.0%
Using feature(s) {2,4,7,10} accuracy is 71.0%
Using feature(s) {2,4,5,10} accuracy is 75.0%
Using feature(s) {2,4,5,7} accuracy is 77.0%

(Warning, Accuracy has decreased!)
Finished search!! The best feature subset is {2,4,5,7,10}, which has an accuracy of 82.0%
